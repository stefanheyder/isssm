# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/30_mode_estimation.ipynb.

# %% auto 0
__all__ = ['vmm', 'vdiag', 'SmoothState', 'PseudoObs', 'PseudoObsCov', 'mode_estimation']

# %% ../nbs/30_mode_estimation.ipynb 7
from .kalman import predict
from jaxtyping import Array, Float
from jax import grad, vmap, jacfwd, jacrev
from functools import partial
import jax.numpy as jnp
import jax.random as jrn

from .typing import InitialState

from .lcssm import nb_lcssm, simulate_lcssm, v_time
from jax.lax import scan
from .kalman import smoother, kalman
from .lcssm import v_time
from jax import grad, jacfwd, jacrev, jit

vmm = jit(vmap(jnp.matmul))
vdiag = jit(vmap(jnp.diag))

SmoothState = Float[Array, "n+1 m"]
PseudoObs = Float[Array, "n+1 p"]
PseudoObsCov = Float[Array, "n+1 p p"]

def mode_estimation(
    y: Float[Array, "n+1 p"], # observation
    x0: InitialState, # initial state mean
    A: Float[Array, "n m m"], # state transition matrices
    Sigma: Float[Array, "n+1 m m"], # state covariance matrices
    B: Float[Array, "n+1 p m"], # observation matrices
    xi_fun, # function mapping time and signal to parameters
    dist, # distribution of observations
    s_init: Float[Array, "n+1 p"], # initial signal
    n_iter: int, # number of iterations
    log_lik=None, # log likelihood function
    d_log_lik=None, # derivative of log likelihood function
    dd_log_lik=None, # second derivative of log likelihood function
) -> tuple[SmoothState, PseudoObs, PseudoObsCov]:
    np1, _ = y.shape
    n = np1 - 1

    def default_log_lik(t, s):
        params = xi_fun(t, s)
        return dist(params).log_prob(y[t]).sum()

    if log_lik is None:
        log_lik = jit(default_log_lik)

    if d_log_lik is None:
        d_log_lik = jit(jacfwd(log_lik, argnums=1))
    if dd_log_lik is None:
        dd_log_lik = jit(jacrev(d_log_lik, argnums=1))

    vd_log_lik = v_time(d_log_lik)
    vdd_log_lik = v_time(dd_log_lik)

    vB = jit(partial(vmm, B))

    def iteration(carry, input):
        (signal,) = carry

        grad = vd_log_lik(jnp.arange(n + 1), signal)
        Gamma = -vdd_log_lik(jnp.arange(n + 1), signal)
        # assume hessian is diagonal
        Omega = vdiag(1.0 / vdiag(Gamma))

        z = signal + vmm(Omega, grad)
        x_filt, Xi_filt, x_pred, Xi_pred = kalman(z, x0, Sigma, Omega, A, B)

        x_smooth, Xi_smooth = smoother(x_filt, Xi_filt, x_pred, Xi_pred, A)

        signal = vB(x_smooth)

        return (signal,), (x_smooth, z, Omega)

    _, (x_smooth, z, Omega) = scan(iteration, (s_init,), (jnp.arange(n_iter),))

    return (x_smooth[-1], z[-1], Omega[-1])
