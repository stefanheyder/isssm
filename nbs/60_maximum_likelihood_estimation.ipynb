{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrn\n",
    "from jax import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from isssm.kalman import kalman\n",
    "from isssm.glssm_models import lcm\n",
    "from isssm.glssm import simulate_glssm\n",
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "import fastcore.test as fct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian linear models\n",
    "\n",
    "For Gaussian linear state space models we can evaluate the likelihood analytically with a single pass of the Kalman filter.\n",
    "Based on the predictions $\\hat Y_{t| t - 1}$ and associated covariance matrices $\\Psi_{t + 1 | t}$ for $t = 0, \\dots n$ produced by the Kalman filter we can derive the gaussian negative log likelihood which is given by the gaussian distribution with that mean and covariance matrix and observation $Y_t$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "vmm = vmap(jnp.matmul, (0,0))\n",
    "\n",
    "def gnll(y, x_pred, Xi_pred, B, Omega):\n",
    "    y_pred = vmm(B, x_pred)\n",
    "    Psi_pred = vmm(vmm(B, Xi_pred), jnp.transpose(B, (0, 2, 1))) + Omega\n",
    "    \n",
    "    return - tfd.MultivariateNormalFullCovariance(y_pred, Psi_pred).log_prob(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "x0, A, B, Sigma, Omega = lcm(1, 0., 1., 1., 1.)\n",
    "_, (y,) = simulate_glssm(x0, A, B, Sigma, Omega, 1, jrn.PRNGKey(34234))\n",
    "\n",
    "x_filt, Xi_filt, x_pred, Xi_pred = kalman(y, x0, Sigma, Omega, A, B)\n",
    "nll = gnll(y, x_pred, Xi_pred, B, Omega)\n",
    "\n",
    "\n",
    "EY = jnp.zeros((2,))\n",
    "CovY = jnp.array([[2., 1.], [1., 3.]])\n",
    "\n",
    "fct.test_eq(nll, -tfd.MultivariateNormalFullCovariance(EY, CovY).log_prob(y.reshape(-1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE in GLSSMs\n",
    "\n",
    "For a parametrized GLSSM, that is a model that depends on parameters $\\theta$, we can use numerical optimization to find the maximum likelihood estimatior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from jax.scipy.optimize import minimize\n",
    "def mle_glssm(y, model, theta0, aux):\n",
    "    def f(theta):\n",
    "        x0, A, B, Sigma, Omega = model(theta, aux)\n",
    "        _, _, x_pred, Xi_pred = kalman(y, x0, Sigma, Omega, A, B)\n",
    "        return gnll(y, x_pred, Xi_pred, B, Omega)\n",
    "\n",
    "    return minimize(f, theta0, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.3734169, 3.719784 ], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "def parameterized_lcm(theta, aux):\n",
    "    log_s2_eps, log_s2_eta = theta\n",
    "    n, x0, s2_x0 = aux\n",
    "\n",
    "    return lcm(n, x0, s2_x0, jnp.exp(log_s2_eps), jnp.exp(log_s2_eta))\n",
    "    \n",
    "theta = jnp.log(jnp.array([2., 3.]))\n",
    "aux = (100, 0., 1.)\n",
    "x0, A, B, Sigma, Omega = parameterized_lcm(theta, aux)\n",
    "_, (y,) = simulate_glssm(x0, A, B, Sigma, Omega, 1, jrn.PRNGKey(15435324))\n",
    "\n",
    "result = mle_glssm(y, parameterized_lcm, jnp.ones(2), aux)\n",
    "jnp.exp(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
